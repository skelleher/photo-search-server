import argparse
import mmap
import numpy as np
import os
import pandas as pd
import sys
import time
from stat import *
from sklearn.neighbors import NearestNeighbors

#
# Load a Database of images, and let clients search them using a query image.
#
# For now this is just a big dumb .CSV file, generated by index.py.
# Database also supports vanilla iteration and indexed access for the REST API.
#

class Database(object):
    def __init__(self, args):
        self._args = args
        self._name = "Database"
        #self.rect = Rect(0, 0, args.width, args.height) 
        print("Database: %s" % (str(args)))


    def load_database(self, database_path):
        print("Database: loading database %s" % database_path)
        #sys.stdout.flush()
    
        try:
            if not os.path.exists(database_path):
                print("Error: %s not found" % database_path)
                return -1
       
            # TODO: prefix database with signature
            mode = os.stat(database_path).st_mode
            if S_ISDIR(mode):
                print("Error: %s is not a valid database" % database_path)
                return -1
                    
        except Exception:
            print("Error loading database %s" % database_path)
            print(type(ex))
            print(ex.args)
            print(ex)
            pass

        self._name = database_path.split(os.path.sep)[-1]

        # Load the features[] column of the database, so we can build a kNN for searching.
        # Also serves as an index to the on-disk database, which contains full paths and metadate for the images.
        #
        # TODO: very obviously this should be refactored into an offline step, not done at load.
        # TODO: very obviously this should use a faster structure for searching; kNN slows to 1+ seconds at 1.2M records.
        # TODO: use Annoy or HNSW for approximate nearest neighbors.
        # How to memory-map large files from Python?
        
        self._index = pd.read_csv(database_path, usecols = ["features"], memory_map = True)
   
        if (self._index.columns.values != ("features")).any():
            print("Database index has unexpected columns: %s" % str(self.index.columns.values))
            return -1

        # Convert from string to ndarray of floats
        print("Converting from ASCII...")
        self._index["features"] = self._index["features"].apply(Database._string_to_float_array)

        # Reshape the DataFrame to a [rows x cols] ndarray that knn requires
        # This is SUPER-HACKY, but it was late on a Saturday night and I needed to move forward.
        self._num_items = len(self._index)
        self._num_features = len(self._index["features"][0])
        new_X = np.ndarray(shape=[self._num_items, self._num_features])

        print("Reshaping...")
        X = self._index["features"].as_matrix()
        for i in range(len(X)):
            f = X[i] # f is a list
            new_X[i] = f.reshape(1, -1)

        X = new_X
        print("Loaded %d rows, %d features" % (self._num_items, self._num_features))

        print("Loading kNN...")
        if self._args.metric == "cosine":
            self._knn = NearestNeighbors(n_neighbors=5, algorithm="auto", metric=metrics.pairwise.cosine_distances, n_jobs=1)
        else:
            self._knn = NearestNeighbors(n_neighbors=5, algorithm="auto", metric="euclidean", n_jobs=1)

#        self.knn = NearestNeighbors(n_neighbors=5, algorithm="ball_tree", metric="euclidean", n_jobs=4)         # also consider Chebyshev
        self._knn.fit(X)
        print(self._knn)

        # Now that we have in-RAM index of image features, keep an open filehandle to the full database on disk
        self._db = open(self._args.database, "rt")
        self._db_mmap = mmap.mmap(self._db.fileno(), 0, access = mmap.ACCESS_READ)


    # Database singleton, for use with a Flask web server, since Flask is stateless between REST calls
#    def get_instance(self):
#        return self


    def query_image(self, feature_vector, k=5):
        if self._args.verbose:
            print("query_image: k=%d" % k)

        start = time.time()
        X = feature_vector

        if self._args.verbose:
            print("feature vector = %s" % str(X.shape))

        X = X.reshape(1, -1)

        neighbors = self._knn.kneighbors(X, k, return_distance=True)
        distances = neighbors[0].squeeze()
        matches = neighbors[1].squeeze()
   
        # Fetch filenames for matching images and return to client
        results = []
        for i in range(len(matches)):
            idx = int(matches[i])

            item = self._get_image_description( idx )

            #print("match[%d] = %d = %s" % (i, idx, item))

            classname, filename, _ = item.split(",")
            classname = classname.strip()
            filename = filename.strip()
            #print("neighbor[%d]: %s %s" % (idx, classname, filename))

            results.append({"idx": idx, "class" : classname, "filename" : filename, "distance" : distances[i]})

        stop = time.time()
        msecs = (stop - start) * 1000
        print("query: %d ms" % msecs)
 
        return results


    def _get_image_description( self, idx ):
        # TODO: seek to database[idx] and read the entry
        # TODO: generate a lookup table (and index into the index >.<) that tells us where to fseek() to.
        header_offset = 28
        features_offset_in_row = 165 # seek past class ID and filename to find the feature vector
        feature_size = 12 # size of a feature vector elelemnt: float printed as %11.6f, plus a space between each feature

        record_length = features_offset_in_row + (feature_size * self._num_features)
        #print("num_features = %d, hack_offset = %d" % (self.num_features, record_length))

        file_offset = header_offset + (idx * record_length)
        self._db_mmap.seek(file_offset)
        item = self._db_mmap.readline()

        item = item.decode( "utf-8" )

        return item


    # Database supports [] operator
    # TODO: return full record from on-disk database, not the in-RAM index which is only a feature vector
    def __getitem__( self, key ):
        if isinstance( key, slice ):
            #return [self._index.iloc[ i ] for i in range( *key.indices(self._num_items) ) ] # assumes Python 3 range()
            return [self._get_image_description( i ) for i in range( *key.indices(self._num_items) ) ]

        if key < 0:
            key += self._num_items
        
        if key < 0 or key >= self._num_items:
            raise IndexError
            
        #return self._index.iloc[ key ]
        return self._get_image_description( key )

    
    # Database is iterable
    def __len__(self):
        return len( self._index )
    
    def __iter__( self ):
        self._idx = 0
        return self
    
    def __next__( self ):
        if self._idx > self._num_items:
            raise StopIteration
            
        #item = self._index.iloc[ self._idx ]
        item = self_get_image_description( self._idx )
        self._idx += 1
        
        return item


    # Convert string to list of floats
    @staticmethod
    def _string_to_float_array(str):
        tokens = str.split()
        ar = np.empty(len(tokens))
    
        for i in range(len(tokens)):
            f = float( tokens[i] )
            ar[i] = f

        return ar

    # Properties
    def _get_name(self):
        return self._name


    def _get_shape(self):
        return (self._num_items, self._num_features)

    name        = property( _get_name, None )
    shape       = property( _get_shape, None )

 
